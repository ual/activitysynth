{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car ownership model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import orca\n",
    "import os; os.chdir('../')\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from urbansim.utils import misc\n",
    "import pandana as pdna\n",
    "from collections import OrderedDict\n",
    "    \n",
    "from urbansim_templates import modelmanager as mm\n",
    "from urbansim_templates.models import LargeMultinomialLogitStep\n",
    "import pandas as pd\n",
    "import orca\n",
    "# import os; os.chdir('/home/juan/activitysynth/')\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "import pylogit as pl                   # For choice model estimation\n",
    "from pylogit import nested_logit as nl # For nested logit convenience funcs\n",
    "import math \n",
    "from collections import OrderedDict \n",
    "\n",
    "import pickle\n",
    "import dill\n",
    "import time\n",
    "import random\n",
    "import scipy.stats as st\n",
    "\n",
    "import urbansim_templates\n",
    "\n",
    "from scripts import datasources, models, variables, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/juan'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_format = 'csv'\n",
    "input_data_dir = '/home/data/spring_2019/base/'\n",
    "\n",
    "formattable_fname_dict = {\n",
    "    'parcels': 'parcels.{0}',\n",
    "    'buildings': 'buildings.{0}',\n",
    "    'jobs': 'jobs.{0}',\n",
    "    'establishments': 'establishments.{0}',\n",
    "    'households': 'households.{0}',\n",
    "    'persons': 'persons.{0}',\n",
    "    'rentals': 'craigslist.{0}',\n",
    "    'units': 'units.{0}',\n",
    "    'mtc_skims': 'mtc_skims.{0}',\n",
    "    'beam_skims_raw': '30.skims-smart-23April2019-baseline.csv.gz',\n",
    "    'beam_skims_imputed': 'beam_skims_imputed.{0}',\n",
    "    # the following nodes and edges .csv's will be phased out and\n",
    "    # replaced by travel model skims entirely\n",
    "    'drive_nodes': 'drive_nodes.{0}',\n",
    "    'drive_edges': 'drive_edges.{0}',\n",
    "    'drive_access_vars': 'drive_net_vars.{0}',\n",
    "    'walk_nodes': 'walk_nodes.{0}',\n",
    "    'walk_edges': 'walk_edges.{0}',\n",
    "    'walk_access_vars': 'walk_net_vars.{0}',\n",
    "    'zones': 'zones.{0}',\n",
    "    'zone_access_vars': 'zones_w_access_vars.{0}',\n",
    "}\n",
    "\n",
    "def format_fname_dict(formattable_fname_dict, format='csv'):\n",
    "    formatted_dict = {\n",
    "        k: v.format('csv')\n",
    "        for k, v in formattable_fname_dict.items()}\n",
    "    return formatted_dict\n",
    "\n",
    "input_fnames = format_fname_dict(\n",
    "            formattable_fname_dict, input_file_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "orca.add_injectable('input_file_format', input_file_format)\n",
    "orca.add_injectable('input_data_dir', input_data_dir)\n",
    "orca.add_injectable('input_fnames', input_fnames)\n",
    "orca.add_injectable('store', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing directory to run the network aggregation steps\n",
    "os.chdir('/home/juan/activitysynth/activitysynth/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step 'initialize_network_small'\n",
      "Time to execute step 'initialize_network_small': 0.00 s\n",
      "Running step 'network_aggregations_small'\n",
      "Computing accessibility variables\n",
      "Computing units_10000\n",
      "Computing units_sf_10000\n",
      "Computing units_mf_10000\n",
      "Computing pop_10000\n",
      "Removed 189769 rows because they contain missing values\n",
      "Computing hh_10000\n",
      "Removed 189769 rows because they contain missing values\n",
      "Computing poor_10000\n",
      "Removed 53114 rows because they contain missing values\n",
      "Computing renters_10000\n",
      "Removed 102597 rows because they contain missing values\n",
      "Computing avg_income_10000\n",
      "Removed 189769 rows because they contain missing values\n",
      "Computing jobs_10000\n",
      "Computing avg_rent_10000\n",
      "Computing med_rent_10000\n",
      "Computing pop_white_10000\n",
      "Removed 107372 rows because they contain missing values\n",
      "Computing pop_black_10000\n",
      "Removed 10541 rows because they contain missing values\n",
      "Computing pop_asian_10000\n",
      "Removed 51048 rows because they contain missing values\n",
      "Computing pop_hisp_10000\n",
      "Removed 31685 rows because they contain missing values\n",
      "Computing units_25000\n",
      "Computing units_sf_25000\n",
      "Computing units_mf_25000\n",
      "Computing pop_25000\n",
      "Removed 189769 rows because they contain missing values\n",
      "Computing hh_25000\n",
      "Removed 189769 rows because they contain missing values\n",
      "Computing poor_25000\n",
      "Removed 53114 rows because they contain missing values\n",
      "Computing renters_25000\n",
      "Removed 102597 rows because they contain missing values\n",
      "Computing avg_income_25000\n",
      "Removed 189769 rows because they contain missing values\n",
      "Computing jobs_25000\n",
      "Computing avg_rent_25000\n",
      "Computing pop_white_25000\n",
      "Removed 107372 rows because they contain missing values\n",
      "Computing pop_black_25000\n",
      "Removed 10541 rows because they contain missing values\n",
      "Computing pop_asian_25000\n",
      "Removed 51048 rows because they contain missing values\n",
      "Computing pop_hisp_25000\n",
      "Removed 31685 rows because they contain missing values\n",
      "Computing jobs_10000_retail\n",
      "Computing jobs_25000_retail\n",
      "Computing jobs_10000_fire\n",
      "Computing jobs_25000_fire\n",
      "Computing jobs_10000_tech\n",
      "Computing jobs_25000_tech\n",
      "Computing jobs_10000_serv\n",
      "Computing jobs_25000_serv\n",
      "         units_10000  units_sf_10000  units_mf_10000      pop_10000  \\\n",
      "count   30826.000000    30826.000000    30826.000000   30826.000000   \n",
      "mean   111655.259521    60758.737592    45983.788815  260258.257023   \n",
      "std     87205.002426    37438.499035    46022.772268  188415.644622   \n",
      "min         0.000000        0.000000        0.000000       0.000000   \n",
      "25%     43964.000000    31220.250000    10558.000000  106529.000000   \n",
      "50%     96857.000000    59397.000000    32540.000000  231992.500000   \n",
      "75%    163123.000000    90067.750000    69669.000000  392372.500000   \n",
      "max    406849.000000   147988.000000   205873.000000  838919.000000   \n",
      "\n",
      "            hh_10000     poor_10000  renters_10000  avg_income_10000  \\\n",
      "count   30826.000000   30826.000000   30826.000000      30826.000000   \n",
      "mean    99092.191721   24263.902939   47250.300298     111232.133257   \n",
      "std     78052.959198   22118.834988   47935.457922      30332.958647   \n",
      "min         0.000000       0.000000       0.000000          0.000000   \n",
      "25%     39191.000000    7995.750000   13226.250000      93100.589083   \n",
      "50%     85632.500000   17593.000000   33265.000000     111716.310346   \n",
      "75%    143063.250000   34092.750000   65630.250000     129610.887845   \n",
      "max    370544.000000  100942.000000  225495.000000     265525.000000   \n",
      "\n",
      "          jobs_10000  avg_rent_10000       ...         pop_asian_25000  \\\n",
      "count   30826.000000    30826.000000       ...            30826.000000   \n",
      "mean   118243.519464     2643.122460       ...           294669.101408   \n",
      "std    107993.608729      776.766843       ...           217585.925381   \n",
      "min         0.000000        0.000000       ...                0.000000   \n",
      "25%     28940.250000     2269.256141       ...            73012.250000   \n",
      "50%     92301.500000     2712.736729       ...           312616.000000   \n",
      "75%    176945.000000     2983.646159       ...           477996.500000   \n",
      "max    428606.000000     7266.666667       ...           693127.000000   \n",
      "\n",
      "       pop_hisp_25000  jobs_10000_retail  jobs_25000_retail  jobs_10000_fire  \\\n",
      "count    30826.000000       30826.000000       30826.000000     30826.000000   \n",
      "mean    183838.911698       15902.012100       55488.349478      8651.443132   \n",
      "std     110234.361576       14105.231994       33838.915279     10033.247270   \n",
      "min          0.000000           0.000000           0.000000         0.000000   \n",
      "25%      88483.750000        4314.000000       21935.500000      2093.000000   \n",
      "50%     181105.000000       13269.500000       61066.000000      5932.500000   \n",
      "75%     298576.750000       21232.750000       87060.000000     10849.000000   \n",
      "max     351717.000000       61048.000000      103899.000000     48870.000000   \n",
      "\n",
      "       jobs_25000_fire  jobs_10000_tech  jobs_25000_tech  jobs_10000_serv  \\\n",
      "count     30826.000000     30826.000000     30826.000000     30826.000000   \n",
      "mean      30371.376533     18321.402161     63953.289593     10136.738240   \n",
      "std       20592.329443     21681.852522     46756.286825     11020.692482   \n",
      "min           0.000000         0.000000         0.000000         0.000000   \n",
      "25%       10928.000000      2208.000000     16480.250000      2744.000000   \n",
      "50%       31111.500000      9152.500000     64664.000000      6776.000000   \n",
      "75%       42117.750000     28647.500000     98836.750000     13249.750000   \n",
      "max       73607.000000    103018.000000    149697.000000     51636.000000   \n",
      "\n",
      "       jobs_25000_serv  \n",
      "count     30826.000000  \n",
      "mean      34163.351489  \n",
      "std       23411.034125  \n",
      "min           0.000000  \n",
      "25%       11541.000000  \n",
      "50%       32524.000000  \n",
      "75%       50603.750000  \n",
      "max       82062.000000  \n",
      "\n",
      "[8 rows x 37 columns]\n",
      "Time to execute step 'network_aggregations_small': 677.69 s\n",
      "Running step 'initialize_network_walk'\n",
      "Time to execute step 'initialize_network_walk': 0.00 s\n",
      "Running step 'network_aggregations_walk'\n",
      "Computing accessibility variables\n",
      "Computing units_500_walk\n",
      "Computing sqft_unit_500_walk\n",
      "Computing singles_500_walk\n",
      "Removed 52084 rows because they contain missing values\n",
      "Computing elderly_hh_500_walk\n",
      "Removed 34553 rows because they contain missing values\n",
      "Computing children_500_walk\n",
      "Removed 189769 rows because they contain missing values\n",
      "Computing units_sf_500_walk\n",
      "Computing units_mf_500_walk\n",
      "Computing pop_500_walk\n",
      "Removed 189769 rows because they contain missing values\n",
      "Computing hh_500_walk\n",
      "Removed 189769 rows because they contain missing values\n",
      "Computing poor_500_walk\n",
      "Removed 53114 rows because they contain missing values\n",
      "Computing rich_500_walk\n",
      "Removed 38964 rows because they contain missing values\n",
      "Computing renters_500_walk\n",
      "Removed 102597 rows because they contain missing values\n",
      "Computing avg_income_500_walk\n",
      "Removed 189769 rows because they contain missing values\n",
      "Computing jobs_500_walk\n",
      "Computing avg_rent_500_walk\n",
      "Computing pop_white_500_walk\n",
      "Removed 107372 rows because they contain missing values\n",
      "Computing pop_black_500_walk\n",
      "Removed 10541 rows because they contain missing values\n",
      "Computing pop_asian_500_walk\n",
      "Removed 51048 rows because they contain missing values\n",
      "Computing pop_hisp_500_walk\n",
      "Removed 31685 rows because they contain missing values\n",
      "Computing units_1500_walk\n",
      "Computing sqft_unit_1500_walk\n",
      "Computing singles_1500_walk\n",
      "Removed 52084 rows because they contain missing values\n",
      "Computing elderly_hh_1500_walk\n",
      "Removed 34553 rows because they contain missing values\n",
      "Computing children_1500_walk\n",
      "Removed 189769 rows because they contain missing values\n",
      "Computing units_sf_1500_walk\n",
      "Computing units_mf_1500_walk\n",
      "Computing pop_1500_walk\n",
      "Removed 189769 rows because they contain missing values\n",
      "Computing hh_1500_walk\n",
      "Removed 189769 rows because they contain missing values\n",
      "Computing poor_1500_walk\n",
      "Removed 53114 rows because they contain missing values\n",
      "Computing rich_1500_walk\n",
      "Removed 38964 rows because they contain missing values\n",
      "Computing renters_1500_walk\n",
      "Removed 102597 rows because they contain missing values\n",
      "Computing avg_income_1500_walk\n",
      "Removed 189769 rows because they contain missing values\n",
      "Computing jobs_1500_walk\n",
      "Computing avg_rent_1500_walk\n",
      "Computing pop_white_1500_walk\n",
      "Removed 107372 rows because they contain missing values\n",
      "Computing pop_black_1500_walk\n",
      "Removed 10541 rows because they contain missing values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pop_asian_1500_walk\n",
      "Removed 51048 rows because they contain missing values\n",
      "Computing pop_hisp_1500_walk\n",
      "Removed 31685 rows because they contain missing values\n",
      "Computing pop_2500_walk\n",
      "Removed 189769 rows because they contain missing values\n",
      "Computing pop_white_2500_walk\n",
      "Removed 107372 rows because they contain missing values\n",
      "Computing pop_black_2500_walk\n",
      "Removed 10541 rows because they contain missing values\n",
      "Computing pop_asian_2500_walk\n",
      "Removed 51048 rows because they contain missing values\n",
      "Computing pop_hisp_2500_walk\n",
      "Removed 31685 rows because they contain missing values\n",
      "Computing jobs_500_walk_retail\n",
      "Computing jobs_1500_walk_retail\n",
      "Computing jobs_2500_walk_retail\n",
      "Computing jobs_500_walk_fire\n",
      "Computing jobs_1500_walk_fire\n",
      "Computing jobs_2500_walk_fire\n",
      "Computing jobs_500_walk_tech\n",
      "Computing jobs_1500_walk_tech\n",
      "Computing jobs_2500_walk_tech\n",
      "Computing jobs_500_walk_serv\n",
      "Computing jobs_1500_walk_serv\n",
      "Computing jobs_2500_walk_serv\n",
      "       units_500_walk  sqft_unit_500_walk  singles_500_walk  \\\n",
      "count   415716.000000       415716.000000     415716.000000   \n",
      "mean       356.025760         1245.303477         94.368742   \n",
      "std       1097.266478          979.057308        344.532606   \n",
      "min          0.000000            0.000000          0.000000   \n",
      "25%          8.000000          455.911149          1.000000   \n",
      "50%        188.000000         1315.697967         27.000000   \n",
      "75%        440.000000         1761.777561         87.000000   \n",
      "max     184977.000000        30000.000000      45805.000000   \n",
      "\n",
      "       elderly_hh_500_walk  children_500_walk  units_sf_500_walk  \\\n",
      "count        415716.000000      415716.000000      415716.000000   \n",
      "mean             58.488439         158.008881         163.913537   \n",
      "std             241.396787         443.206144         704.706968   \n",
      "min               0.000000           0.000000           0.000000   \n",
      "25%               1.000000           3.000000           2.000000   \n",
      "50%              28.000000          92.000000          98.000000   \n",
      "75%              70.000000         231.000000         247.000000   \n",
      "max           41743.000000       81187.000000      136953.000000   \n",
      "\n",
      "       units_mf_500_walk   pop_500_walk    hh_500_walk  poor_500_walk  \\\n",
      "count      415716.000000  415716.000000  415716.000000  415716.000000   \n",
      "mean          165.691405     792.425952     315.910172      85.848214   \n",
      "std           469.461483    2241.623502     957.091514     320.291735   \n",
      "min             0.000000       0.000000       0.000000       0.000000   \n",
      "25%             0.000000      20.000000       7.000000       1.000000   \n",
      "50%             2.000000     462.000000     170.000000      25.000000   \n",
      "75%           159.000000    1085.000000     395.000000      83.000000   \n",
      "max         48024.000000  396939.000000  162454.000000   42782.000000   \n",
      "\n",
      "              ...           jobs_2500_walk_retail  jobs_500_walk_fire  \\\n",
      "count         ...                   415716.000000       415716.000000   \n",
      "mean          ...                     1581.179690           53.885460   \n",
      "std           ...                     3031.162291          429.421888   \n",
      "min           ...                        0.000000            0.000000   \n",
      "25%           ...                      223.000000            0.000000   \n",
      "50%           ...                      842.000000            3.000000   \n",
      "75%           ...                     1990.000000           23.000000   \n",
      "max           ...                    35933.000000        20526.000000   \n",
      "\n",
      "       jobs_1500_walk_fire  jobs_2500_walk_fire  jobs_500_walk_tech  \\\n",
      "count        415716.000000        415716.000000       415716.000000   \n",
      "mean            420.179305           979.940062          106.490318   \n",
      "std            1996.134238          3203.315346          791.083748   \n",
      "min               0.000000             0.000000            0.000000   \n",
      "25%              19.000000           112.000000            0.000000   \n",
      "50%             101.000000           366.000000            4.000000   \n",
      "75%             278.000000           857.000000           30.000000   \n",
      "max           34721.000000         38378.000000        31572.000000   \n",
      "\n",
      "       jobs_1500_walk_tech  jobs_2500_walk_tech  jobs_500_walk_serv  \\\n",
      "count        415716.000000        415716.000000       415716.000000   \n",
      "mean            815.705017          1950.765186           60.123912   \n",
      "std            3808.003905          6458.022536          270.243780   \n",
      "min               0.000000             0.000000            0.000000   \n",
      "25%              25.000000           126.000000            0.000000   \n",
      "50%             117.000000           455.000000            0.000000   \n",
      "75%             463.000000          1449.000000           35.000000   \n",
      "max           68294.000000         77926.000000        12480.000000   \n",
      "\n",
      "       jobs_1500_walk_serv  jobs_2500_walk_serv  \n",
      "count        415716.000000        415716.000000  \n",
      "mean            436.386119          1104.828303  \n",
      "std            1438.848663          2959.981741  \n",
      "min               0.000000             0.000000  \n",
      "25%              12.000000           116.000000  \n",
      "50%             127.000000           494.000000  \n",
      "75%             416.000000          1108.000000  \n",
      "max           25447.000000         34317.000000  \n",
      "\n",
      "[8 rows x 55 columns]\n",
      "Time to execute step 'network_aggregations_walk': 511.91 s\n",
      "Running step 'initialize_imputed_skims'\n",
      "No imputed skims found. Creating them now.\n",
      "Time to execute step 'initialize_imputed_skims': 87.02 s\n",
      "Running step 'skims_aggregations'\n",
      "Time to execute step 'skims_aggregations': 0.00 s\n",
      "Total time to execute iteration 1 with iteration value None: 1276.62 s\n"
     ]
    }
   ],
   "source": [
    "orca.run(['initialize_network_small', 'network_aggregations_small', #Drivving Accesibility variables\n",
    "          'initialize_network_walk', 'network_aggregations_walk', #Walking accesibility variables\n",
    "          'initialize_imputed_skims','skims_aggregations']) # Beam-based accesibility varaibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tables\n",
    "table_list = ['households', 'persons', 'nodessmall', 'nodeswalk', 'zones', 'access_indicators_ampeak', 'parcels']\n",
    "\n",
    "households = orca.get_table('households').to_frame()\n",
    "persons = orca.get_table('persons').to_frame()\n",
    "nodessmall = orca.get_table('nodessmall').to_frame()\n",
    "nodeswalk = orca.get_table('nodeswalk').to_frame()\n",
    "zones = orca.get_table('zones').to_frame()\n",
    "transit = orca.get_table('access_indicators_ampeak').to_frame()\n",
    "parcels = orca.get_table('parcels').to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# orca.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding variables to the model \n",
    "#Person table \n",
    "@orca.column('persons', cache=True)\n",
    "def children(persons):\n",
    "    return [1 if x < 18 else 0 for x in persons.age]\n",
    "\n",
    "@orca.column('persons', cache=True)\n",
    "def children(persons):\n",
    "    return [1 if x < 18 else 0 for x in persons.age]\n",
    "\n",
    "@orca.column('persons')\n",
    "def age_0_15(persons):\n",
    "    return  (persons.age.between(0,15, inclusive = True )).astype(int)\n",
    "\n",
    "@orca.column('persons')\n",
    "def age_16_17(persons):\n",
    "    return  (persons.age.between(16,17, inclusive = True )).astype(int)\n",
    "\n",
    "@orca.column('persons')\n",
    "def age_18_25(persons):\n",
    "    return  (persons.age.between(18,25, inclusive = True )).astype(int)\n",
    "\n",
    "@orca.column('persons')\n",
    "def age_26_40(persons):\n",
    "    return  (persons.age.between(26,40, inclusive = True )).astype(int)\n",
    "\n",
    "@orca.column('persons')\n",
    "def age_41_60(persons):\n",
    "    return  (persons.age.between(41,60, inclusive = True )).astype(int)\n",
    "\n",
    "@orca.column('persons')\n",
    "def age_60(persons):\n",
    "    return  (persons.age.between(61,100, inclusive = True )).astype(int)\n",
    "\n",
    "@orca.column('persons')\n",
    "def worker_student(persons):\n",
    "    return  (persons.worker * persons.student).astype(int)\n",
    "\n",
    "@orca.column('persons')\n",
    "def non_worker_non_student(persons):\n",
    "    return  ((~persons.worker.astype(bool))*(~persons.student.astype(bool))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# persons = orca.get_table('persons').to_frame()\n",
    "# persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<orca.orca.DataFrameWrapper at 0x7f4bdde61710>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating person-based variables to merge onto Household table\n",
    "# Missing variables>> Parcel ID\n",
    "\n",
    "person_var = persons.groupby(by ='household_id').agg({'age': 'max',\n",
    "                                                    'zone_id_home': 'first',\n",
    "                                                    'children':'sum',\n",
    "                                                    'age_0_15': 'sum',\n",
    "                                                    'age_16_17': 'sum',\n",
    "                                                    'age_18_25': 'sum',\n",
    "                                                    'age_26_40': 'sum',\n",
    "                                                    'age_41_60': 'sum',\n",
    "                                                    'age_60': 'sum', \n",
    "                                                    'non_worker_non_student': 'sum',\n",
    "                                                    'worker_student':'sum',\n",
    "                                                    'worker': 'sum',\n",
    "                                                    'student': 'sum'})\n",
    "\n",
    "orca.add_table('person_var', person_var);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Broadcasting \n",
    "orca.broadcast(cast = 'nodessmall', onto = 'households', cast_index = True, onto_on = 'node_id_small')\n",
    "orca.broadcast(cast = 'nodesewalk', onto = 'households', cast_index = True, onto_on = 'node_id_wlak')\n",
    "orca.broadcast(cast = 'person_var', onto = 'households', cast_index = True, onto_index = True)\n",
    "\n",
    "# parcels_acc = orca.merge_tables(target = 'parcels', tables = ['parcels', 'nodessmall', 'nodeswalk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_merge = orca.merge_tables(target = 'households', \n",
    "                  tables = ['zones', 'parcels', 'buildings', 'units','nodessmall', \n",
    "                            'nodeswalk','person_var', 'households'],) \n",
    "#                   columns = ['zone_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting hispanic head variable as a dummy variable\n",
    "final_merge['hisp_head'] = final_merge.hispanic_head.map({'no': 0, 'yes': 1})\n",
    "\n",
    "#Deleting object type  columns\n",
    "drop_var = list(final_merge.loc[:,list(final_merge.dtypes[final_merge.dtypes == 'object'].index)])\n",
    "final_merge.drop(columns=drop_var, inplace= True)\n",
    "\n",
    "#New cateforization for number of cars per household\n",
    "final_merge['cars'] = final_merge['cars'].apply(lambda x: 0*(x==0)+ 1*(x==1)+ 2*(x==2)+3*(x>=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting variables names for each data source\n",
    "accessibility_var = set(parcels_acc) - set(parcels)\n",
    "parcel_var = set(parcels.columns) - set(accessibility_var)\n",
    "skim_accessibility = set(skim_based_accessibilities.columns)\n",
    "households_var_continious = ['INCOM','AGE', 'children']#, 'TransitPass'] # ,'PERNO', 'EMPLY'                   \n",
    "households_var_dummy = ['max_35', 'age_0_15', \n",
    "                    'age_16_17', 'age_18_25', 'age_25_40','age_40_60',\n",
    "                    'age_60', 'worker_student', 'non_worker_non_student',\n",
    "                   'worker','student','RESTY', 'TEN']#, 'HHLIC', ]\n",
    "dependent_var = ['cars_alt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    ''' \n",
    "    Normalizes values in a Series\n",
    "    Input: \n",
    "    data: Series-like\n",
    "    \n",
    "    Return: Normalized Series-like object\n",
    "    '''\n",
    "    if data.dtype == 'O':\n",
    "        return 0\n",
    "    else:\n",
    "        return (data - np.mean(data)) / np.std(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['zones', 'parcels', 'buildings', 'units','nodessmall', \n",
    "                            'nodeswalk','person_var', 'households'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_var = set(households)-{'state','serialno','income_10','income_12','income_12p','income_2',\n",
    "                 'income_4', 'income_6', 'income_8','hh_inc_150kplus','hh_inc_25_to_75k',\n",
    "                 'hh_inc_75_to_200k','hh_inc_under_25k', 'hh_size_1per','hh_size_over_4',\n",
    "                 'building_type_2','node_id_small','node_id_walk','single_family',\n",
    "                 'single_family_int','tenure_1','tenure_2','tenure_3','tenure_4','unit_id',\n",
    "                 'block_group','block_group_id', 'hispanic_head', 'county','tract'}\n",
    "zone_var = set(zones)-{'acres'}\n",
    "parcel_var =set(parcels)-{'node_id','node_id_small','node_id_walk','shape_area','x','y',\n",
    "                          'zone_id', 'apn', 'parcel_id_local', 'block_id','imputation_flag'}\n",
    "\n",
    "per_var = set(person_var)-{'zone_id_home'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vars = set(list(hh_var) + list(zone_var) +list(parcel_var) + list(per_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = final_merge.loc[:,list(final_vars)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(parcels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent_mover\n",
      "proportion_undevelopable\n",
      "tenure\n",
      "tax_exempt_status\n"
     ]
    }
   ],
   "source": [
    "for x in df.columns:\n",
    "    if len(df[x].unique()) <= 2:\n",
    "        print (x)\n",
    "#     print (x, len(df[x].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hispanic_head'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_mover, proportion_undevelopable, tax_exempt_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "households.tenure.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merge is complete. \n",
    ">> Run the ML algrotihms for a feature selction\n",
    ">> Run a real model using pylogit instead of statmodels\n",
    ">> Save the pickle file and run simulation. Do a step for simulation and add it to the run.py\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
